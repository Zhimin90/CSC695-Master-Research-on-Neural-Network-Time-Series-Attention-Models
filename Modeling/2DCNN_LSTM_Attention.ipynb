{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "Asset_PATH = \"/home/zhimin90/DePaul/CSC695/Github/CSC695-Masters-Research-on-Neural-Network-Time-Series-Attention-Models/Asset/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Gaussian KDE timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "density_matrix_t_series = pickle.load(open(Asset_PATH  + 'density_matrix_t_series_100x100.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(198, 100, 100)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "density_matrix_t_series.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019.7794007598727\n",
      "-2.393156546274511e-13\n"
     ]
    }
   ],
   "source": [
    "print(np.max(density_matrix_t_series))\n",
    "print(np.min(density_matrix_t_series))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "198"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "density_matrix_t_series.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = 52"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid = (60,20)\n",
    "test = 20\n",
    "\n",
    "total_len = density_matrix_t_series.shape[0] - timesteps\n",
    "train_index = range(0,int(train/100*total_len))\n",
    "\n",
    "valid_index = range(train_index[-1]+1,train_index[-1] + int(valid/100*total_len))\n",
    "test_index = range(valid_index[-1]+1,valid_index[-1] + int(test/100*total_len))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(198, 10000)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flattened_matrix_np = np.reshape(density_matrix_t_series, \n",
    "                                 (density_matrix_t_series.shape[0],\n",
    "                                  density_matrix_t_series.shape[1]*density_matrix_t_series.shape[2]))\n",
    "flattened_matrix_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1935.6194220503628"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(flattened_matrix_np[train_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_max = np.max(flattened_matrix_np[train_index])\n",
    "scaler_min = np.min(flattened_matrix_np[train_index])\n",
    "\n",
    "X_train = (flattened_matrix_np[train_index] - scaler_min)/(scaler_max - scaler_min)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87, 1, 10000)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0],\n",
    "                          1,    \n",
    "                          X_train.shape[1])\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87, 1, 100, 100, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0],X_train.shape[1],int(X_train.shape[2]**(1/2)),int(X_train.shape[2]**(1/2)),1)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(np.max(X_train))\n",
    "print(np.min(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We transform the whole train, valid, test based on scaler fitted on train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2019.7794007598727"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(flattened_matrix_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flattened_matrix_np.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_flattened_matrix = (flattened_matrix_np - scaler_min)/(scaler_max - scaler_min)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(198, 10000)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flattened_matrix_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(198, 10000)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_flattened_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0434796105839654\n",
      "-3.2227207716804404e-17\n"
     ]
    }
   ],
   "source": [
    "print(np.max(scaled_flattened_matrix))\n",
    "print(np.min(scaled_flattened_matrix))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(198, 10000)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_flattened_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def window_stack(a, stepsize=1, width=52):\n",
    "    n = a.shape[0]\n",
    "    return np.hstack( a[i:1+n+i-width:stepsize] for i in range(0,width) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zhimin90/anaconda3/envs/venv/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "stacked = window_stack(scaled_flattened_matrix,1,timesteps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(147, 520000)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stacked.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshape_stack = stacked.reshape(stacked.shape[0],timesteps,\n",
    "                                int((stacked.shape[1]/timesteps)**(1/2)),\n",
    "                                int((stacked.shape[1]/timesteps)**(1/2)),1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(147, 52, 100, 100, 1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reshape_stack.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We reshape to (sample, timestep, inputshape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(147, 52, 100, 100, 1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled_flattened_matrix = reshape_stack\n",
    "scaled_flattened_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid = (60,20)\n",
    "test = 20\n",
    "\n",
    "total_len = scaled_flattened_matrix.shape[0]\n",
    "train_index = range(0,int(train/100*total_len))\n",
    "\n",
    "valid_index = range(train_index[-1]+1,train_index[-1] + int(valid/100*total_len))\n",
    "test_index = range(valid_index[-1]+1,valid_index[-1] + int(test/100*total_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We set the target to be 7 days aggregated KDE or 1 single frame forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = scaled_flattened_matrix[np.array(train_index)]\n",
    "Y_train = scaled_flattened_matrix[np.array(train_index)+1][:,-1,:]\n",
    "Y_train = Y_train.reshape(Y_train.shape[0],int(Y_train.shape[1]*Y_train.shape[2]*Y_train.shape[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = scaled_flattened_matrix[np.array(valid_index)]\n",
    "Y_valid = scaled_flattened_matrix[np.array(valid_index)+1][:,-1,:]\n",
    "Y_valid = Y_valid.reshape(Y_valid.shape[0],int(Y_valid.shape[1]*Y_valid.shape[2]*Y_valid.shape[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = scaled_flattened_matrix[np.array(test_index)]\n",
    "Y_test = scaled_flattened_matrix[np.array(test_index)+1][:,-1,:]\n",
    "Y_test = Y_test.reshape(Y_test.shape[0],int(Y_test.shape[1]*Y_test.shape[2]*Y_test.shape[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88, 52, 100, 100, 1)\n",
      "(88, 10000)\n",
      "(28, 52, 100, 100, 1)\n",
      "(28, 10000)\n",
      "(28, 52, 100, 100, 1)\n",
      "(28, 10000)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(Y_valid.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, LSTM, Bidirectional, GaussianNoise, Flatten, Input\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Concatenate, Input, LSTM, RepeatVector, TimeDistributed\n",
    "import tensorflow.keras.layers as layers\n",
    "from tensorflow.keras.layers import concatenate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = Asset_PATH+'checkpoints/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2D CNN LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"2DCNN_LTSM\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 52, 100, 100 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed (TimeDistribut (None, 52, 100, 100, 40          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_1 (TimeDistrib (None, 52, 100, 100, 420         time_distributed[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_2 (TimeDistrib (None, 52, 50, 50, 2 0           time_distributed_1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_4 (TimeDistrib (None, 52, 50, 50, 2 420         time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_5 (TimeDistrib (None, 52, 50, 50, 2 420         time_distributed_4[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_6 (TimeDistrib (None, 52, 25, 25, 2 0           time_distributed_5[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_3 (TimeDistrib (None, 52, 50000)    0           time_distributed_2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "time_distributed_7 (TimeDistrib (None, 52, 12500)    0           time_distributed_6[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 52, 62500)    0           time_distributed_3[0][0]         \n",
      "                                                                 time_distributed_7[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "lstm (LSTM)                     (None, 50)           12510200    concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 100)          5100        lstm[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 100)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 10000)        1010000     flatten_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 13,526,600\n",
      "Trainable params: 13,526,600\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "serie_size, time_step, n_features_row, n_features_column, no_channel = X_train.shape\n",
    "\n",
    "epochs = 100\n",
    "batch = 48\n",
    "lr = .001\n",
    "loss='mae'\n",
    "METRIC_ACCURACY = 'mae'\n",
    "'''\n",
    "model = Sequential()\n",
    "\n",
    "model.add(\n",
    "    TimeDistributed(\n",
    "        Conv2D(20, (1,1), activation='relu', \n",
    "               padding='same', \n",
    "               input_shape=(n_features_row, n_features_column, no_channel)),\n",
    "               input_shape=(time_step,n_features_row, n_features_column, no_channel)))\n",
    "model.add(\n",
    "    TimeDistributed(\n",
    "        Conv2D(20, (1,1), activation='relu', \n",
    "               padding='same', \n",
    "               input_shape=(n_features_row, n_features_column, no_channel)),\n",
    "               input_shape=(time_step,n_features_row, n_features_column, no_channel)))\n",
    "\n",
    "model.add(\n",
    "    TimeDistributed(\n",
    "        MaxPooling2D(pool_size=(2, 2))))\n",
    "        \n",
    "model.add(TimeDistributed(Flatten()))\n",
    "\n",
    "\n",
    "#model.add(TimeDistributed(Flatten(),input_shape=(time_step,n_features_row, n_features_column, no_channel)))\n",
    "\n",
    "#model.add(LSTM(50,return_sequences=True))\n",
    "model.add(LSTM(50))\n",
    "#model.add(Dense(100, kernel_initializer='glorot_normal', activation='relu'))\n",
    "\n",
    "#model.add(Flatten())\n",
    "\n",
    "model.add(Dense(Y_train.shape[1]))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "adam = optimizers.Adam(lr)\n",
    "model.compile(loss='mean_absolute_error',\n",
    "                   metrics=['mae'], \n",
    "                   optimizer=adam)\n",
    "'''\n",
    "\n",
    "inputs = Input(shape=(time_step,n_features_row, n_features_column, no_channel))\n",
    "\n",
    "cnn1 = Conv2D(20, (1,1), activation='relu', padding='same')\n",
    "TD = TimeDistributed(cnn1)(inputs)\n",
    "\n",
    "cnn2 = Conv2D(20, (1,1), activation='relu', padding='same')\n",
    "TD2 = TimeDistributed(cnn2)(TD)\n",
    "\n",
    "TD3 = TimeDistributed(\n",
    "        MaxPooling2D(pool_size=(2, 2)))(TD2)\n",
    "    \n",
    "timeDist = TimeDistributed(Flatten())(TD3)\n",
    "\n",
    "cnn4 = Conv2D(20, (1,1), activation='relu', padding='same')\n",
    "TD4 = TimeDistributed(cnn4)(TD3)\n",
    "\n",
    "cnn5 = Conv2D(20, (1,1), activation='relu', padding='same')\n",
    "TD5 = TimeDistributed(cnn5)(TD4)\n",
    "\n",
    "TD6 = TimeDistributed(\n",
    "        MaxPooling2D(pool_size=(2, 2)))(TD5)\n",
    "    \n",
    "timeDist2 = TimeDistributed(Flatten())(TD6)\n",
    "\n",
    "merge = concatenate([timeDist, timeDist2])\n",
    "\n",
    "LSTM_layer1 = LSTM(50)(merge)\n",
    "Dense1 = Dense(100, kernel_initializer='glorot_normal', activation='relu')(LSTM_layer1)\n",
    "Dense2 = Dense(Y_train.shape[1])(Flatten()(Dense1))\n",
    "outputs = Dense2\n",
    "\n",
    "model = Model(inputs, outputs, name=\"2DCNN_LTSM\")\n",
    "model.summary()\n",
    "\n",
    "adam = optimizers.Adam(lr)\n",
    "model.compile(loss='mean_absolute_error',\n",
    "                   metrics=['mae'], \n",
    "                   optimizer=adam)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n",
      "Train on 88 samples, validate on 28 samples\n",
      "Epoch 1/20\n",
      "88/88 [==============================] - 2s 20ms/sample - loss: 0.0040 - mae: 0.0040 - val_loss: 0.0034 - val_mae: 0.0034\n",
      "Epoch 2/20\n",
      "88/88 [==============================] - 2s 19ms/sample - loss: 0.0030 - mae: 0.0030 - val_loss: 0.0027 - val_mae: 0.0027\n",
      "Epoch 3/20\n",
      "88/88 [==============================] - 2s 19ms/sample - loss: 0.0025 - mae: 0.0025 - val_loss: 0.0024 - val_mae: 0.0024\n",
      "Epoch 4/20\n",
      "88/88 [==============================] - 2s 19ms/sample - loss: 0.0022 - mae: 0.0022 - val_loss: 0.0022 - val_mae: 0.0022\n",
      "Epoch 5/20\n",
      "88/88 [==============================] - 2s 19ms/sample - loss: 0.0021 - mae: 0.0021 - val_loss: 0.0021 - val_mae: 0.0021\n",
      "Epoch 6/20\n",
      "88/88 [==============================] - 2s 19ms/sample - loss: 0.0020 - mae: 0.0020 - val_loss: 0.0021 - val_mae: 0.0021\n",
      "Epoch 7/20\n",
      "88/88 [==============================] - 2s 20ms/sample - loss: 0.0020 - mae: 0.0020 - val_loss: 0.0020 - val_mae: 0.0020\n",
      "Epoch 8/20\n",
      "88/88 [==============================] - 2s 19ms/sample - loss: 0.0020 - mae: 0.0020 - val_loss: 0.0020 - val_mae: 0.0020\n",
      "Epoch 9/20\n",
      "88/88 [==============================] - 2s 19ms/sample - loss: 0.0019 - mae: 0.0019 - val_loss: 0.0020 - val_mae: 0.0020\n",
      "Epoch 10/20\n",
      "88/88 [==============================] - 2s 19ms/sample - loss: 0.0019 - mae: 0.0019 - val_loss: 0.0020 - val_mae: 0.0020\n",
      "Epoch 11/20\n",
      "88/88 [==============================] - 2s 19ms/sample - loss: 0.0019 - mae: 0.0019 - val_loss: 0.0020 - val_mae: 0.0020\n",
      "Epoch 12/20\n",
      "88/88 [==============================] - 2s 19ms/sample - loss: 0.0019 - mae: 0.0019 - val_loss: 0.0019 - val_mae: 0.0019\n",
      "Epoch 13/20\n",
      "88/88 [==============================] - 2s 20ms/sample - loss: 0.0019 - mae: 0.0019 - val_loss: 0.0019 - val_mae: 0.0019\n",
      "Epoch 14/20\n",
      "88/88 [==============================] - 2s 19ms/sample - loss: 0.0018 - mae: 0.0018 - val_loss: 0.0019 - val_mae: 0.0019\n",
      "Epoch 15/20\n",
      "88/88 [==============================] - 2s 19ms/sample - loss: 0.0018 - mae: 0.0018 - val_loss: 0.0019 - val_mae: 0.0019\n",
      "Epoch 16/20\n",
      "88/88 [==============================] - 2s 19ms/sample - loss: 0.0018 - mae: 0.0018 - val_loss: 0.0019 - val_mae: 0.0019\n",
      "Epoch 17/20\n",
      "88/88 [==============================] - 2s 19ms/sample - loss: 0.0018 - mae: 0.0018 - val_loss: 0.0019 - val_mae: 0.0019\n",
      "Epoch 18/20\n",
      "88/88 [==============================] - 2s 19ms/sample - loss: 0.0018 - mae: 0.0018 - val_loss: 0.0019 - val_mae: 0.0019\n",
      "Epoch 19/20\n",
      "88/88 [==============================] - 2s 19ms/sample - loss: 0.0018 - mae: 0.0018 - val_loss: 0.0019 - val_mae: 0.0019\n",
      "Epoch 20/20\n",
      "88/88 [==============================] - 2s 20ms/sample - loss: 0.0018 - mae: 0.0018 - val_loss: 0.0019 - val_mae: 0.0019\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 5\n",
    "\n",
    "earlystop_callback = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\",\n",
    "    min_delta=0,\n",
    "    patience=EPOCHS*10,\n",
    "    verbose=1,\n",
    "    mode=\"auto\",\n",
    "    baseline=None,\n",
    "    restore_best_weights=True,)\n",
    "\n",
    "logdir = os.path.join(\"./logs\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "tensorboard_cbk = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
    "\n",
    "modelfilename = checkpoint_filepath + '_'+\\\n",
    "                    datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\\\n",
    "                    + \"_model.hdf5\"\n",
    "\n",
    "model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    modelfilename,\n",
    "    save_weights_only=False,\n",
    "    monitor='val_mae',#'val_accuracy',\n",
    "    mode='min',\n",
    "    verbose=1,\n",
    "    period = 1,\n",
    "    save_best_only=True)\n",
    "\n",
    "\n",
    "\n",
    "model_history = model.fit(X_train,Y_train, \n",
    "                             validation_data=(X_valid, Y_valid),\n",
    "                             epochs=20, \n",
    "                             batch_size=10, \n",
    "                             callbacks=[tensorboard_cbk,\n",
    "                             #hp.KerasCallback(logdir, hparams),\n",
    "                             #earlystop_callback,\n",
    "                             #model_checkpoint_callback\n",
    "                                       ]\n",
    "                                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28/28 - 0s - loss: 0.0019 - mae: 0.0019\n",
      "valid_accuracy_MAE=0.0018834175, valid_loss=0.0018834174843505025\n"
     ]
    }
   ],
   "source": [
    "valid_loss, valid_acc = model.evaluate(X_valid, Y_valid, verbose=2) # 5/2020 nt: use validation set\n",
    "print (\"valid_accuracy_MAE=%s, valid_loss=%s\" % (valid_acc, valid_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 9176), started 0:08:55 ago. (Use '!kill 9176' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-ad4f26c091b32363\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-ad4f26c091b32363\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          url.port = 6006;\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "  "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the TensorBoard notebook extension\n",
    "%load_ext tensorboard\n",
    "logs_base_dir = \"./logs\"\n",
    "os.makedirs(logs_base_dir, exist_ok=True)\n",
    "%tensorboard --logdir {logs_base_dir}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Predict = model.predict(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Predict.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(Predict[-1].shape[0]**(1/2)),int(Predict[-1].shape[0]**(1/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshapePred(Predict):\n",
    "    return np.rot90(Predict[-1].reshape(int(Predict[-1].shape[0]**(1/2)),int(Predict[-1].shape[0]**(1/2))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "grid_size = 500\n",
    "density_matrix_t_series = []\n",
    "# Define the borders\n",
    "x = [-87.9361,-87.5245]\n",
    "y = [41.6447,42.023]\n",
    "deltaX = (max(x) - min(x))/10\n",
    "deltaY = (max(y) - min(y))/10\n",
    "xmin = min(x) - deltaX\n",
    "xmax = max(x) + deltaX\n",
    "ymin = min(y) - deltaY\n",
    "ymax = max(y) + deltaY\n",
    "plt.figure(figsize=(18, 14))\n",
    "plt.title('Predicted')\n",
    "plt.imshow( X=reshapePred(Predict), cmap=plt.cm.twilight, extent=[xmin, xmax, ymin, ymax])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 14))\n",
    "plt.title('Actual')\n",
    "plt.imshow( X=reshapePred(Y_valid), cmap=plt.cm.twilight, extent=[xmin, xmax, ymin, ymax])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:venv]",
   "language": "python",
   "name": "conda-env-venv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
